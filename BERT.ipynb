{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "7q2g86uhlwHP",
    "outputId": "e3ddb850-54ca-47fc-c9c5-458b4c09b60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: filelock in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (19.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (4.36.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from transformers) (1.16.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: click in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: six in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\mukuu\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVy1rLijRaqe"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3lms6qCXtYd"
   },
   "source": [
    "# 一个简单的BERT处理输入的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249,
     "referenced_widgets": [
      "529cfc7d6019485b919f86fb0985d3d5",
      "0f17a01b80af4e81a91aeff5918f0e76",
      "e0b6fecf9e9342adbc69318fef1d201e",
      "ebb8a08c6de74e16a46c00352499e5e3",
      "76481615b7134304bfef1e3e8638aac9",
      "66c0e0f2851c4fa9a21f7357f53b3f62",
      "24864c50de634b27942cb9872adb4ade",
      "5a3410c3fed14751bef950ff0841888e",
      "e1f3663c1d384d95be2733168e0021b7",
      "9069701c30e5402f8dbf397184605467",
      "8175c331ffcb45be8c6e48996eb10342",
      "75ad5163ae744af098fd3677eee67675",
      "0c2e4133eceb43e293328f6cb7459466",
      "e09709281cce4690817303c53328eaa7",
      "9ddbb625df0448eb8c8893a0019ccfc5",
      "a29182a5a7b74cd18bcd5fa5ee106496",
      "9c4d2740c25649c09bbfac6a8c28cc3d",
      "d1dd51ec11d74aa486a7a245d21d2651",
      "337fb33c2cd7458b9a9a0218b303f5ed",
      "4543347cccf541a0b466be3938f88412",
      "6301e7a013e0445bb7ce5f8f7f852c66",
      "0a65ec1d33624b4098e82deabb94748c",
      "1bc69a34990244ce91bf03013d0faefe",
      "641bbaa1b1d34aa9b89b3241275365e9"
     ]
    },
    "colab_type": "code",
    "id": "OrRh25riXP3E",
    "outputId": "e77d3f15-1b00-499c-e68b-cc6786e16650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.']\n",
      "['[CLS]', 'i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]']\n",
      "['[CLS]', 'i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "[101, 1045, 2428, 5632, 2023, 3185, 1037, 2843, 1012, 102, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练BERT模型和分词器\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 分词\n",
    "sentence = 'I really enjoyed this movie a lot.'\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)\n",
    "# Out: ['i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.']\n",
    "\n",
    "# Token embedding: 添加开头和结尾的tokens\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "print(tokens)\n",
    "# Out: ['[CLS]', 'i', 'really', 'enjoyed', 'this', 'movie', 'a', 'lot', '.', '[SEP]']\n",
    "\n",
    "# 进行Padding保证所有输入的文本长度相同\n",
    "MAX_LEN = 12\n",
    "padded_tokens = tokens + ['[PAD]' for _ in range(MAX_LEN - len(tokens))]\n",
    "print(padded_tokens)\n",
    "\n",
    "# 用0标注告诉BERT哪些是PAD\n",
    "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "print(attn_mask)\n",
    "# Out: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
    "\n",
    "# segment embedding\n",
    "seg_ids = [0 for _ in range(len(padded_tokens))] #Since we only have a single sequence as input\n",
    "\n",
    "# positional embedding: 获取tokens在vocabulary中的id\n",
    "sent_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "print(sent_ids)\n",
    "\n",
    "# Converting everything to torch tensors before feeding them to bert_model\n",
    "sent_ids = torch.tensor(sent_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "attn_mask = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "seg_ids   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "\n",
    "#Feed them to bert\n",
    "hidden_reps, cls_head = bert_model(sent_ids, attention_mask = attn_mask,\\\n",
    "                                  token_type_ids = seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_rjnXIWNhlR"
   },
   "source": [
    "# 数据类，用于加载csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4A2LhsheAUj"
   },
   "outputs": [],
   "source": [
    "class OFFdataset(Dataset):\n",
    "    def __init__(self, dataframe, maxlen):\n",
    "\n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        self.df = dataframe\n",
    "\n",
    "        self.mapping = {'OFF': 0, 'NOT': 1, 'TIN': 0, 'UNT': 1, 'IND': 0, 'GRP': 1, 'OTH': 2}\n",
    "        \n",
    "        #Initialize the BERT tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df['text'][index]\n",
    "        label = self.df.iloc[:,2][index]\n",
    "        label =  torch.tensor(int(self.mapping[label]))\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        try:\n",
    "          tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
    "        except:\n",
    "          #  避免文本为nan值报错\n",
    "          tokens = []\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "        \n",
    "        return tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0H4Yzn8bf_9u"
   },
   "source": [
    "# 指定task，准备数据，分配sampler权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "onpNJMP2eHDn",
    "outputId": "eb32616a-9569-4f1b-911a-ca2226b8a334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 188029\n"
     ]
    }
   ],
   "source": [
    "# 指定task和文件名\n",
    "path = r'C:\\Users\\Mukuu\\Desktop\\MSc Proj'\n",
    "#TASK = 'c'\n",
    "#data_df = pd.read_csv(path + 'final_train_%s.csv' % TASK)[['tweet','subtask_%s' % TASK]]\n",
    "#test_df = pd.read_csv(path + 'final_test_%s.csv' % TASK)\n",
    "\n",
    "#data_df = pd.read_csv(path + '\\sample2_cleaned.csv')\n",
    "#test_df = pd.read_csv(path + '\\sample2_cleaned_test.csv')\n",
    "# task_a_distant_cleaned.csv\n",
    "data_df = pd.read_csv(path + r'\\task_b_distant_cleaned.csv')\n",
    "test_df = pd.read_csv(path + r'\\task_a_distant_cleaned_test.csv')\n",
    "\n",
    "# 定义类名和数字的映射关系\n",
    "mapping = {'OFF': 0, 'NOT': 1, 'TIN': 0, 'UNT': 1, 'IND': 0, 'GRP': 1, 'OTH': 2}\n",
    "        \n",
    "train_split = 0.995  # Defines the ratio of train/valid\n",
    "train_size = int(len(data_df) * train_split)\n",
    "valid_size = int(len(data_df) * (1-train_split))\n",
    "print('train size:',train_size)\n",
    "train_df = data_df[:train_size].reset_index(drop=True)\n",
    "valid_df = data_df[train_size:].reset_index(drop=True)\n",
    "#Creating instances of training and validation set\n",
    "train_set = OFFdataset(train_df, maxlen = 30)\n",
    "val_set   = OFFdataset(valid_df, maxlen = 30)\n",
    "test_set  = OFFdataset(test_df, maxlen = 30)\n",
    "\n",
    "# adjust the weight for unbalanced class distribution\n",
    "train_batch_size = 32\n",
    "#class_count = train_df['subtask_%s' % TASK].value_counts()\n",
    "# weights = 1 / torch.Tensor([class_count[0],class_count[1]])\n",
    "#weights = 1 / torch.Tensor([cnt for cnt in class_count])\n",
    "# sample_weights = train_df['subtask_%s' % TASK].map(lambda x: weights[1] if x == 1 else weights[0])\n",
    "#sample_weights = train_df['subtask_%s' % TASK].map(lambda x: weights[mapping[x]])\n",
    "#sample_weights = torch.tensor(sample_weights)\n",
    "#sampler = torch.utils.data.sampler.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "# trainloader = data_utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, sampler = sampler)\n",
    "\n",
    "# 要使用重新分配权重的版本，在train_loader的参数重添加 sampler=sampler\n",
    "#Creating intsances of training and validation dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = train_batch_size, num_workers = 0)\n",
    "val_loader =   DataLoader(val_set, batch_size = 64, num_workers = 0)\n",
    "test_loader =  DataLoader(test_set, batch_size = 64, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzmhOk80iICv"
   },
   "source": [
    "# 合并预训练的BERT和输出用全连层，准备进行Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQM6rswvb9ww"
   },
   "outputs": [],
   "source": [
    "# 为BERT端添加用于最后输出的全连接层以构成分类器\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, freeze_bert = True):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Freeze bert layers\n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                if (random.random()>0.3):\n",
    "                    p.requires_grad = False\n",
    "        \n",
    "        #Classification layer\n",
    "        self.cls_layer = nn.Linear(768, 1536)\n",
    "        self.dp1 = nn.Dropout(0.3)\n",
    "        self.cls_layer2 = nn.Linear(4096, 2048)\n",
    "        self.dp2 = nn.Dropout(0.3)\n",
    "        self.bn = nn.BatchNorm1d(768, momentum=0.01)\n",
    "        self.bn2 = nn.BatchNorm1d(1536, momentum=0.01)\n",
    "        self.cls_layer3 = nn.Linear(1536, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        logits = cont_reps[:, 0]\n",
    "        # logits = self.dp1(logits)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        # cls_rep = self.bn(cls_rep)\n",
    "        logits = self.cls_layer(logits)\n",
    "        \n",
    "        # # logits = self.cls_layer2(logits)\n",
    "        logits = self.bn2(logits)\n",
    "        # logits = self.dp2(logits)\n",
    "        \n",
    "        logits = self.cls_layer3(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0LyJIEfnJhV"
   },
   "source": [
    "# 备选结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OO7s_khNnEvV"
   },
   "outputs": [],
   "source": [
    "# 为BERT端添加用于最后输出的全连接层以构成分类器\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "class BertLSTM(nn.Module):\n",
    "    def __init__(self, freeze_bert = True):\n",
    "        super(BertLSTM, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Freeze bert layers\n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                if (random.random()>0.3):\n",
    "                    p.requires_grad = False\n",
    "        \n",
    "        self.embed_size = 768\n",
    "        self.hidden_size = 512\n",
    "        self.num_layers = 1\n",
    "        \n",
    "        #Classification layer\n",
    "        self.cls_layer = nn.Linear(768, 1536)\n",
    "        self.dp1 = nn.Dropout(0.3)\n",
    "        self.cls_layer2 = nn.Linear(4096, 2048)\n",
    "        self.dp2 = nn.Dropout(0.5)\n",
    "        self.cls_layer3 = nn.Linear(self.hidden_size * 2, 2)\n",
    "\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embed_size, self.hidden_size, self.num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        with torch.no_grad():\n",
    "            logits, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        # logits = self.dp1(cont_reps)\n",
    "\n",
    "        _,(logits,_) = self.lstm(logits)\n",
    "        logits = self.dp1(\n",
    "            torch.cat((logits[-2, :, :], logits[-1, :, :]), dim=1))\n",
    "        logits = self.cls_layer3(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsYpnZaTr1Lc"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = SentimentClassifier(freeze_bert = False)\n",
    "net = net.to(device)\n",
    "# 指定损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwwGZtZH_OTK"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "best_model_acc = copy.deepcopy(net)\n",
    "best_model_loss = copy.deepcopy(net)\n",
    "best_acc = 0\n",
    "best_loss = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKqRbIJmPsrR"
   },
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "k4JcoBFwadl7",
    "outputId": "962710de-da94-46fc-aa13-820d42e5eae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 79.27011585235596\n",
      "Iteration 588 of epoch 1. Loss : 0.5858968700580045 Accuracy : 0.7943770885467529\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.4459746951148624 ValAcc : 0.8201058506965637\n",
      "time: 169.4553325176239\n",
      "Iteration 1176 of epoch 1. Loss : 0.4871995422963788 Accuracy : 0.8073979616165161\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.37317042981506027 ValAcc : 0.8433862328529358\n",
      "time: 259.14591693878174\n",
      "Iteration 1763 of epoch 1. Loss : 0.44546877965964987 Accuracy : 0.8076964020729065\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.37139619292405546 ValAcc : 0.8232804536819458\n",
      "time: 356.86969327926636\n",
      "Iteration 2351 of epoch 1. Loss : 0.4207242337732506 Accuracy : 0.8071299195289612\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3500153314499628 ValAcc : 0.8455026745796204\n",
      "time: 450.5688166618347\n",
      "Iteration 2938 of epoch 1. Loss : 0.40217939846171985 Accuracy : 0.8074583411216736\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3855709237396402 ValAcc : 0.7968254089355469\n",
      "time: 542.6551461219788\n",
      "Iteration 3526 of epoch 1. Loss : 0.3892349101945344 Accuracy : 0.8070316910743713\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3404675690585343 ValAcc : 0.8455026745796204\n",
      "time: 632.0244724750519\n",
      "Iteration 4114 of epoch 1. Loss : 0.3788698466624168 Accuracy : 0.8058459162712097\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3153074345260701 ValAcc : 0.8645502924919128\n",
      "time: 725.9974682331085\n",
      "Iteration 4701 of epoch 1. Loss : 0.37322030004079837 Accuracy : 0.8033663034439087\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3170962409367637 ValAcc : 0.8613756895065308\n",
      "time: 822.0913162231445\n",
      "Iteration 5289 of epoch 1. Loss : 0.3676661019878929 Accuracy : 0.8015456199645996\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3167908925858755 ValAcc : 0.8645502924919128\n",
      "time: 897.7460281848907\n",
      "Iteration 5876 of epoch 1. Loss : 0.36238206649887633 Accuracy : 0.8007892370223999\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tValLoss : 0.3113599797405263 ValAcc : 0.8645502924919128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "898.8251445293427"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs = 1\n",
    "for ep in range(epochs):\n",
    "    correct = 0\n",
    "    train_loss_sum = 0\n",
    "    for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "        #Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, attn_masks)\n",
    "\n",
    "        #Computing loss\n",
    "        loss = criterion(logits, labels)\n",
    "        train_loss_sum += loss.item()\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        optimizer.step()\n",
    "        logits[logits>0.0] = 0.0\n",
    "        logits[logits<0.0] = 1.0\n",
    "        correct += torch.sum(logits[:,0] == labels)\n",
    "        if (it + 1.01) % (train_size/train_batch_size/10) < 1:\n",
    "            acc = correct.float()/((it+1)*train_batch_size)\n",
    "            print('time:',time.time()- start)\n",
    "            print(\"\\rIteration {} of epoch {}. Loss : {} Accuracy : {}\".format(it+1, ep+1, train_loss_sum/(it+1), acc))\n",
    "            val_correct = 0\n",
    "            val_loss_sum = 0\n",
    "            total_valid = 0\n",
    "            for it2, (seq2, attn_masks2, labels2) in enumerate(val_loader):\n",
    "                seq2, attn_masks2, labels2 = seq2.cuda(), attn_masks2.cuda(), labels2.cuda()\n",
    "                val_outputs = net(seq2, attn_masks2)\n",
    "                val_loss = criterion(val_outputs, labels2)\n",
    "                val_loss_sum += val_loss.item()\n",
    "                _, val_preds = torch.max(val_outputs, 1)\n",
    "                val_correct += torch.sum(val_preds == labels2)\n",
    "                # val_outputs[val_outputs>-0.1] = 0.0\n",
    "                # val_outputs[val_outputs<-0.1] = 1.0\n",
    "                total_valid += labels2.size(0)\n",
    "                # val_correct += torch.sum(val_outputs[:,0] == labels2)\n",
    "                \n",
    "            val_epoch_acc = val_correct.float() / total_valid\n",
    "            val_epoch_loss = val_loss_sum/ (total_valid/64)\n",
    "            if val_epoch_acc > best_acc:\n",
    "                best_acc = val_epoch_acc\n",
    "                best_model_acc = copy.deepcopy(net)\n",
    "            if val_epoch_loss < best_loss:\n",
    "                best_loss = val_epoch_loss\n",
    "                best_model_loss = copy.deepcopy(net)\n",
    "            print(\"\\r\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tValLoss : {} ValAcc : {}\".format(val_epoch_loss, val_epoch_acc))\n",
    "duration = time.time() - start\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "O7_KwLj9gMyv",
    "outputId": "75f151df-3d43-414a-f622-da9b49d35ab8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         0], device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(val_outputs, 1)[1],labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path + r'\\test_b_tweets_cleaned.csv')\n",
    "test_set  = OFFdataset(test_df, maxlen = 30)\n",
    "test_loader =  DataLoader(test_set, batch_size = 64, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQewtrIjihKK"
   },
   "source": [
    "# 测试best model在test set上的成绩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BhG2Uu1dW1JS",
    "outputId": "ef8a8054-a981-423f-9f2e-6405c6061d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:185, FP:82, TN:768, FN:387\n",
      "Recall(P):0.323, Recall(N):0.904, Recall-macro:0.613 \n",
      "Precision(P):0.693, Precision(N):0.665, Precision-macro:0.679 \n",
      "F1(P):0.441, F1(N):0.766, F1-macro:0.604\n",
      "Test Loss : 0.978 Test acc : 0.670\n"
     ]
    }
   ],
   "source": [
    "output_data = np.array([])\n",
    "val_correct = 0\n",
    "val_loss = 0\n",
    "total_valid = 0\n",
    "true_label = np.array([])\n",
    "TP,FP,TN,FN =0,0,0,0\n",
    "\n",
    "for it2, (seq2, attn_masks2, labels2) in enumerate(test_loader):\n",
    "    seq2, attn_masks2, labels2 = seq2.cuda(), attn_masks2.cuda(), labels2.cuda()\n",
    "    true_label= np.append(true_label,labels2.cpu().detach().numpy())\n",
    "    val_outputs = best_model_acc(seq2, attn_masks2)\n",
    "    val_loss1 = criterion(val_outputs, labels2)\n",
    "    val_loss += val_loss1.item()\n",
    "    val_outputs[:,0] += 0.0\n",
    "    # val_outputs[val_outputs>-0.0] = 0.0\n",
    "    # val_outputs[val_outputs<-0.0] = 1.0\n",
    "    _, val_preds = torch.max(val_outputs, 1)\n",
    "    val_correct += torch.sum(val_preds == labels2)\n",
    "    valans = val_preds\n",
    "    \n",
    "    total_valid += labels2.size(0)\n",
    "    TP += torch.sum(valans[valans==1.0] == labels2[valans==1.0]).item()\n",
    "    FP += torch.sum(valans[valans==1.0] != labels2[valans==1.0]).item()\n",
    "    TN += torch.sum(valans[valans==0.0] == labels2[valans==0.0]).item()\n",
    "    FN += torch.sum(valans[valans==0.0] != labels2[valans==0.0]).item()\n",
    "\n",
    "    output_data=np.append(output_data, valans.cpu().detach().numpy())\n",
    "\n",
    "print('TP:%d, FP:%d, TN:%d, FN:%d' % (TP,FP,TN,FN))\n",
    "\n",
    "p_recall = TP/(TP+FN)\n",
    "n_recall = TN/(TN+FP) \n",
    "\n",
    "p_precision = TP/(TP+FP)\n",
    "n_precision = TN/(TN+FN) \n",
    "\n",
    "p_f1 = 2*TP/(2*TP+FP+FN)\n",
    "n_f1 = 2*TN/(2*TN+FN+FP) \n",
    "\n",
    "print('Recall(P):%.3f, Recall(N):%.3f, Recall-macro:%.3f '% (p_recall, n_recall,(p_recall + n_recall)/2))\n",
    "print('Precision(P):%.3f, Precision(N):%.3f, Precision-macro:%.3f '% (p_precision, n_precision,(p_precision+n_precision)/2))\n",
    "print('F1(P):%.3f, F1(N):%.3f, F1-macro:%.3f' % (p_f1, n_f1, (p_f1+n_f1)/2))\n",
    "val_epoch_acc = val_correct.float() / total_valid\n",
    "val_epoch_loss = val_loss/ (total_valid/64)\n",
    "print(\"Test Loss : %.3f Test acc : %.3f\" % (val_epoch_loss, val_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_label)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix->\n",
      "  [[768  82]\n",
      " [387 185]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1b38c444a7f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"confusion matrix->\\n \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'OFF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NOT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m plot_confusion_matrix(cm,\n\u001b[0m\u001b[0;32m      5\u001b[0m                           \u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                           \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Confusion matrix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(true_label, output_data)\n",
    "print(\"confusion matrix->\\n \", confusion_matrix(true_label, output_data))\n",
    "target_names = ['OFF', 'NOT']\n",
    "plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "L_SMfujebM31",
    "outputId": "b2e570bb-4567-4989-c193-fe8ccae4883f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "output_data = np.array([])\n",
    "val_correct = 0\n",
    "val_loss = 0\n",
    "total_valid = 0\n",
    "TP,FP,TN,FN =0,0,0,0\n",
    "for it2, (seq2, attn_masks2, labels2) in enumerate(test_loader):\n",
    "    seq2, attn_masks2, labels2 = seq2.cuda(), attn_masks2.cuda(), labels2.cuda()\n",
    "    val_outputs = best_model_acc(seq2, attn_masks2)\n",
    "    val_loss1 = criterion(val_outputs, labels2)\n",
    "    val_loss += val_loss1.item()\n",
    "    val_outputs[:,0] += 0.0\n",
    "    # val_outputs[val_outputs>-0.0] = 0.0\n",
    "    # val_outputs[val_outputs<-0.0] = 1.0\n",
    "    _, val_preds = torch.max(val_outputs, 1)\n",
    "    val_correct += torch.sum(val_preds == labels2)\n",
    "    valans = val_preds\n",
    "    \n",
    "    total_valid += labels2.size(0)\n",
    "\n",
    "    output_data=np.append(output_data, valans.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "ANS_PATH = path + 'labels-level%s.csv' % TASK\n",
    "answer = pd.read_csv(ANS_PATH, header=None)\n",
    "mapping = {'a': {'OFF': 1, 'NOT': 0}, 'b': {'TIN': 1, 'UNT': 0}, 'c': {'IND': 0, 'GRP': 1, 'OTH': 2}}\n",
    "answer[1] = answer[1].map(lambda x: mapping[TASK][x])\n",
    "\n",
    "print(\"Accuracy Score -> \", accuracy_score(answer[1], output_data))\n",
    "print(\"precision Score -> \", precision_score(answer[1], output_data, average='macro'))\n",
    "print(\"recall Split -> \", recall_score(answer[1], output_data, average=None))\n",
    "print(\"recall Macro -> \", recall_score(answer[1], output_data, average='macro'))\n",
    "print(\"F1-Split -> \", f1_score(answer[1], output_data, average=None))\n",
    "print(\"F1-Macro -> \", f1_score(answer[1], output_data, average='macro'))\n",
    "print(\"confusion matrix->\\n \", confusion_matrix(answer[1], output_data))\n",
    "val_epoch_acc = val_correct.float() / total_valid\n",
    "val_epoch_loss = val_loss/ (total_valid/64)\n",
    "print(\"Test Loss : %.3f Test acc : %.3f\" % (val_epoch_loss, val_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "1c04ttpxR7nv",
    "outputId": "788e65b6-fcdc-4b66-aaa1-7e356d69af59"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "output_data = np.array([])\n",
    "val_correct = 0\n",
    "val_loss = 0\n",
    "total_valid = 0\n",
    "TP,FP,TN,FN =0,0,0,0\n",
    "for it2, (seq2, attn_masks2, labels2) in enumerate(test_loader):\n",
    "    seq2, attn_masks2, labels2 = seq2.cuda(), attn_masks2.cuda(), labels2.cuda()\n",
    "    val_outputs = best_model_loss(seq2, attn_masks2)\n",
    "    val_loss1 = criterion(val_outputs, labels2)\n",
    "    val_loss += val_loss1.item()\n",
    "    val_outputs[:,0] += 0.0\n",
    "    # val_outputs[val_outputs>-0.0] = 0.0\n",
    "    # val_outputs[val_outputs<-0.0] = 1.0\n",
    "    _, val_preds = torch.max(val_outputs, 1)\n",
    "    val_correct += torch.sum(val_preds == labels2)\n",
    "    valans = val_preds\n",
    "    \n",
    "    total_valid += labels2.size(0)\n",
    "\n",
    "    output_data=np.append(output_data, valans.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "ANS_PATH = path + 'labels-level%s.csv' % TASK\n",
    "answer = pd.read_csv(ANS_PATH, header=None)\n",
    "mapping = {'a': {'OFF': 1, 'NOT': 0}, 'b': {'TIN': 1, 'UNT': 0}, 'c': {'IND': 0, 'GRP': 1, 'OTH': 2}}\n",
    "answer[1] = answer[1].map(lambda x: mapping[TASK][x])\n",
    "\n",
    "print(\"Accuracy Score -> \", accuracy_score(answer[1], output_data))\n",
    "print(\"precision Score -> \", precision_score(answer[1], output_data, average='macro'))\n",
    "print(\"recall Split -> \", recall_score(answer[1], output_data, average=None))\n",
    "print(\"recall Macro -> \", recall_score(answer[1], output_data, average='macro'))\n",
    "print(\"F1-Split -> \", f1_score(answer[1], output_data, average=None))\n",
    "print(\"F1-Macro -> \", f1_score(answer[1], output_data, average='macro'))\n",
    "print(\"confusion matrix->\\n \", confusion_matrix(answer[1], output_data))\n",
    "val_epoch_acc = val_correct.float() / total_valid\n",
    "val_epoch_loss = val_loss/ (total_valid/64)\n",
    "print(\"Test Loss : %.3f Test acc : %.3f\" % (val_epoch_loss, val_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "akMdPoR79zLW",
    "outputId": "0264fa80-459b-45bb-f822-f8c365c9d2b5"
   },
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "vXs3rjkxkAhZ",
    "outputId": "9283b5b9-b440-447c-d9f4-70d7d911e882"
   },
   "outputs": [],
   "source": [
    "output_data = np.array([])\n",
    "val_correct = 0\n",
    "val_loss = 0\n",
    "total_valid = 0\n",
    "TP,FP,TN,FN =0,0,0,0\n",
    "for it2, (seq2, attn_masks2, labels2) in enumerate(test_loader):\n",
    "    seq2, attn_masks2, labels2 = seq2.cuda(), attn_masks2.cuda(), labels2.cuda()\n",
    "    val_outputs = best_model_loss(seq2, attn_masks2)\n",
    "    val_loss1 = criterion(val_outputs, labels2)\n",
    "    val_loss += val_loss1.item()\n",
    "    val_outputs[:,1] += 0.0\n",
    "    # val_outputs[val_outputs>-0.0] = 0.0\n",
    "    # val_outputs[val_outputs<-0.0] = 1.1\n",
    "    _, val_preds = torch.max(val_outputs, 1)\n",
    "    val_correct += torch.sum(val_preds == labels2)\n",
    "    valans = val_preds\n",
    "    \n",
    "    total_valid += labels2.size(0)\n",
    "    TP += torch.sum(valans[valans==1.0] == labels2[valans==1.0]).item()\n",
    "    FP += torch.sum(valans[valans==1.0] != labels2[valans==1.0]).item()\n",
    "    TN += torch.sum(valans[valans==0.0] == labels2[valans==0.0]).item()\n",
    "    FN += torch.sum(valans[valans==0.0] != labels2[valans==0.0]).item()\n",
    "\n",
    "    output_data=np.append(output_data, valans.cpu().detach().numpy())\n",
    "\n",
    "print('TP:%d, FP:%d, TN:%d, FN:%d' % (TP,FP,TN,FN))\n",
    "\n",
    "p_recall = TP/(TP+FN)\n",
    "n_recall = TN/(TN+FP) \n",
    "\n",
    "p_precision = TP/(TP+FP)\n",
    "n_precision = TN/(TN+FN) \n",
    "\n",
    "p_f1 = 2*TP/(2*TP+FP+FN)\n",
    "n_f1 = 2*TN/(2*TN+FN+FP) \n",
    "\n",
    "print('Recall(OFF):%.3f, Recall(NOT):%.3f, Recall-macro:%.3f '% (p_recall, n_recall,(p_recall + n_recall)/2))\n",
    "print('Precision(OFF):%.3f, Precision(NOT):%.3f, Precision-macro:%.3f '% (p_precision, n_precision,(p_precision+n_precision)/2))\n",
    "print('F1(OFF):%.3f, F1(NOT):%.3f, F1-macro:%.3f' % (p_f1, n_f1, (p_f1+n_f1)/2))\n",
    "val_epoch_acc = val_correct.float() / total_valid\n",
    "val_epoch_loss = val_loss/ (total_valid/32)\n",
    "print(\"Test Loss : {} Test acc : {}\".format(val_epoch_loss, val_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Kwr_3rA57nu7",
    "outputId": "9db99c16-f269-4409-ad71-77f3c52e526b"
   },
   "outputs": [],
   "source": [
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "wevQWfKO6JvK",
    "outputId": "9fca963a-09ae-4245-d000-5b998618876c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9579, -1.1993],\n",
       "        [ 1.2467, -1.4037],\n",
       "        [ 0.8473, -0.7620],\n",
       "        [ 0.4997, -0.8071],\n",
       "        [ 1.1288, -1.8218],\n",
       "        [ 1.1589, -1.0631],\n",
       "        [ 1.1304, -1.3127],\n",
       "        [ 1.4880, -1.0801],\n",
       "        [ 1.2937, -1.6105],\n",
       "        [ 0.8625, -1.1630],\n",
       "        [ 0.7311, -1.0373],\n",
       "        [ 1.5489, -1.4207],\n",
       "        [ 1.1483, -1.2670],\n",
       "        [ 1.0335, -1.1892],\n",
       "        [ 0.8731, -1.2020],\n",
       "        [ 1.4522, -1.4780],\n",
       "        [ 1.5092, -1.3331],\n",
       "        [ 0.5293, -0.9135],\n",
       "        [ 1.4824, -1.1390],\n",
       "        [ 0.9275, -1.1968],\n",
       "        [ 1.0774, -0.7347],\n",
       "        [ 1.6984, -1.6076],\n",
       "        [ 1.2736, -1.6458],\n",
       "        [ 1.0814, -1.3105],\n",
       "        [ 0.7948, -1.2855],\n",
       "        [ 1.1271, -1.1959],\n",
       "        [ 0.6966, -0.9912],\n",
       "        [ 1.6566, -1.3208],\n",
       "        [ 1.0835, -0.9662],\n",
       "        [ 1.2925, -1.4433],\n",
       "        [ 1.3297, -1.6926],\n",
       "        [ 0.5157, -0.7049],\n",
       "        [ 0.7713, -0.6838],\n",
       "        [ 1.6383, -1.6433],\n",
       "        [ 1.6215, -0.8151],\n",
       "        [-0.3981, -0.0694],\n",
       "        [ 1.6151, -1.4971],\n",
       "        [ 1.5203, -1.3311],\n",
       "        [ 0.8326, -1.2928],\n",
       "        [ 1.3782, -1.9470],\n",
       "        [ 1.3601, -1.4664],\n",
       "        [ 1.4304, -1.2532],\n",
       "        [ 0.4222, -1.0129],\n",
       "        [ 2.0046, -1.2293],\n",
       "        [ 1.2400, -1.2799],\n",
       "        [ 0.1930, -0.5187],\n",
       "        [ 1.5911, -1.3504],\n",
       "        [ 0.5542, -0.9909]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUlI3n5s4H-W"
   },
   "source": [
    "输出预测csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRy1dS3wdTMA"
   },
   "outputs": [],
   "source": [
    "output_csv = pd.DataFrame(output_data,columns=['predicted'])\n",
    "output_csv['predicted']=output_csv['predicted'].map(lambda x: 'OFF' if x==1 else 'NOT') \n",
    "output_csv.to_csv('output_bert_b.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHbMJ_BXhGao"
   },
   "outputs": [],
   "source": [
    "numDataPoints = 1000\n",
    "data_dim = 5\n",
    "bs = 100\n",
    " \n",
    "# Create dummy data with class imbalance 9 to 1\n",
    "data = torch.FloatTensor(numDataPoints, data_dim)\n",
    "target = np.hstack((np.zeros(int(numDataPoints * 0.9), dtype=np.int32),\n",
    "     np.ones(int(numDataPoints * 0.1), dtype=np.int32)))\n",
    " \n",
    "\n",
    "class_sample_count = np.array(\n",
    " [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in target])\n",
    " \n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weight = samples_weight.double()\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    " \n",
    "target = torch.from_numpy(target).long()\n",
    "train_dataset = torch.utils.data.TensorDataset(data, target)\n",
    " \n",
    "train_loader = DataLoader(\n",
    " train_dataset, batch_size=bs, num_workers=1, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SxflTlxahc5v",
    "outputId": "30e572e6-bd10-43ee-efd4-a015b02c8eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0001, 0.0001, 0.0001,  ..., 0.0001, 0.0001, 0.0001])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT-OffensEval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a65ec1d33624b4098e82deabb94748c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c2e4133eceb43e293328f6cb7459466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0f17a01b80af4e81a91aeff5918f0e76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bc69a34990244ce91bf03013d0faefe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24864c50de634b27942cb9872adb4ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "337fb33c2cd7458b9a9a0218b303f5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a65ec1d33624b4098e82deabb94748c",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6301e7a013e0445bb7ce5f8f7f852c66",
      "value": 231508
     }
    },
    "4543347cccf541a0b466be3938f88412": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_641bbaa1b1d34aa9b89b3241275365e9",
      "placeholder": "​",
      "style": "IPY_MODEL_1bc69a34990244ce91bf03013d0faefe",
      "value": " 232k/232k [00:00&lt;00:00, 1.69MB/s]"
     }
    },
    "529cfc7d6019485b919f86fb0985d3d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0b6fecf9e9342adbc69318fef1d201e",
       "IPY_MODEL_ebb8a08c6de74e16a46c00352499e5e3"
      ],
      "layout": "IPY_MODEL_0f17a01b80af4e81a91aeff5918f0e76"
     }
    },
    "5a3410c3fed14751bef950ff0841888e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6301e7a013e0445bb7ce5f8f7f852c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "641bbaa1b1d34aa9b89b3241275365e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66c0e0f2851c4fa9a21f7357f53b3f62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ad5163ae744af098fd3677eee67675": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a29182a5a7b74cd18bcd5fa5ee106496",
      "placeholder": "​",
      "style": "IPY_MODEL_9ddbb625df0448eb8c8893a0019ccfc5",
      "value": " 440M/440M [00:18&lt;00:00, 23.6MB/s]"
     }
    },
    "76481615b7134304bfef1e3e8638aac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8175c331ffcb45be8c6e48996eb10342": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e09709281cce4690817303c53328eaa7",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c2e4133eceb43e293328f6cb7459466",
      "value": 440473133
     }
    },
    "9069701c30e5402f8dbf397184605467": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c4d2740c25649c09bbfac6a8c28cc3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_337fb33c2cd7458b9a9a0218b303f5ed",
       "IPY_MODEL_4543347cccf541a0b466be3938f88412"
      ],
      "layout": "IPY_MODEL_d1dd51ec11d74aa486a7a245d21d2651"
     }
    },
    "9ddbb625df0448eb8c8893a0019ccfc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a29182a5a7b74cd18bcd5fa5ee106496": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1dd51ec11d74aa486a7a245d21d2651": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e09709281cce4690817303c53328eaa7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0b6fecf9e9342adbc69318fef1d201e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66c0e0f2851c4fa9a21f7357f53b3f62",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76481615b7134304bfef1e3e8638aac9",
      "value": 433
     }
    },
    "e1f3663c1d384d95be2733168e0021b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8175c331ffcb45be8c6e48996eb10342",
       "IPY_MODEL_75ad5163ae744af098fd3677eee67675"
      ],
      "layout": "IPY_MODEL_9069701c30e5402f8dbf397184605467"
     }
    },
    "ebb8a08c6de74e16a46c00352499e5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a3410c3fed14751bef950ff0841888e",
      "placeholder": "​",
      "style": "IPY_MODEL_24864c50de634b27942cb9872adb4ade",
      "value": " 433/433 [00:21&lt;00:00, 20.4B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
